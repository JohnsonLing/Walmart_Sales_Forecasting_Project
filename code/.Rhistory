n = length(dWeeklySales.ts)
nValid
nTrain = n - nValid
nTrain
WeeklySales.train = window(WeeklySales.ts,
start = c(2010,7),
end = c(2010,5+nTrain))
WeeklySales.train = window(dWeeklySales.ts,
start = c(2010,7),
end = c(2010,5+nTrain))
WeeklySales.train
nTrain
WeeklySales.test = window(dWeeklySales.ts,
start = c(2010,5+nTrain+1))
WeeklySales.test
nValid
WeeklySales.train = window(dWeeklySales.ts,
start = c(2010,7),
end = c(2010,6+nTrain))
WeeklySales.test = window(dWeeklySales.ts,
start = c(2010,6+nTrain+1))
WeeklySales.test
WeeklySales.train
par(mfrow = c(1,2))
Acf(WeeklySales.train, 36, main = "")
Pacf(WeeklySales.train, 36, main = "")
par(mfrow = c(1,1))
m1 = Arima(WeeklySales.ts,
order = c(1,0,1))
summary(m1)
m1.predict <- forecast(m1, h=52, level = 0)
autoplot(WeeklySales.ts)+
autolayer(m1.predict, series = 'Predicted')
m1 = Arima(WeeklySales.ts,
order = c(1,0,1))
m1.predict <- forecast(m1, h=52, level = 0)
m2 = Arima(WeeklySales.train,
order = c(1,0,1))
m2.predict <- forecast(m2, h = 43, level = 0)
autoplot(WeeklySales.train)+
autolayer(WeeklySales.test, series = 'Actual')+
autolayer(m2.predict, series = 'Predicted')
# Read Clean
data = read.csv("Walmart.csv", header = T)
# Read Clean
data = read.csv(".\Walmart.csv", header = T)
# Read Clean
data = read.csv("../Walmart.csv", header = T)
head(data,3)
# Create Time Target (143 weeks, 45 stores in total)
data$week = rep(1:143,45)
data$week
# Data Weekly Average Calculation
data_clean = aggregate(data, list(DateAgg = data$Date), mean)
index.ord = order(data_clean$week)
data_clean = data_clean[index.ord,]
data_clean = data_clean[,c(1,4,5,6,7,8,9)]
# New Dataset: Only Include DataAgg, Weekly_Sales, Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment
head(data_clean,5)
WeeklySales.ts = ts(data_clean$Weekly_Sales, start = c(2010,6), frequency = 52)
plot(WeeklySales.ts)
plot(WeeklySales.ts)
WeeklySales.ts
View(data_clean)
data_clean <- data%>%group_by(Date) %>%
summarise(Weekly_Sales = sum(Weekly_Sales),
Holiday_Flag = mean(Holiday_Flag),
Temperature = mean(Temperature),
Fuel_Price = mean(Fuel_Price),
CPI = mean(CPI),
Unemployment = mean(Unemployment),
.groups = 'drop')
require(dplyr)
data_clean <- data%>%group_by(Date) %>%
summarise(Weekly_Sales = sum(Weekly_Sales),
Holiday_Flag = mean(Holiday_Flag),
Temperature = mean(Temperature),
Fuel_Price = mean(Fuel_Price),
CPI = mean(CPI),
Unemployment = mean(Unemployment),
.groups = 'drop')
data_clean <- data_clean[order(data_clean$week),]
data_clean <- data%>%group_by(Date) %>%
summarise(Weekly_Sales = sum(Weekly_Sales),
week = mean(week),
Holiday_Flag = mean(Holiday_Flag),
Temperature = mean(Temperature),
Fuel_Price = mean(Fuel_Price),
CPI = mean(CPI),
Unemployment = mean(Unemployment),
.groups = 'drop')
data_clean <- data_clean[order(data_clean$week),]
View(data_clean)
data_clean <- data%>%group_by(Date) %>%
summarise(Weekly_Sales = sum(Weekly_Sales),
week = mean(week),
Holiday_Flag = mean(Holiday_Flag),
Temperature = mean(Temperature),
Fuel_Price = mean(Fuel_Price),
CPI = mean(CPI),
Unemployment = mean(Unemployment),
.groups = 'drop')
data_clean2 <- data_clean[order(data_clean$week),]
# Data Weekly Average Calculation
data_clean = aggregate(data, list(DateAgg = data$Date), mean)
index.ord = order(data_clean$week)
data_clean = data_clean[index.ord,]
data_clean = data_clean[,c(1,4,5,6,7,8,9)]
# New Dataset: Only Include DataAgg, Weekly_Sales, Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment
head(data_clean,5)
View(data_clean)
View(data_clean2)
data_clean <- data%>%group_by(Date) %>%
summarise(Weekly_Sales = mean(Weekly_Sales),
week = mean(week),
Holiday_Flag = mean(Holiday_Flag),
Temperature = mean(Temperature),
Fuel_Price = mean(Fuel_Price),
CPI = mean(CPI),
Unemployment = mean(Unemployment),
.groups = 'drop')
data_clean2 <- data_clean[order(data_clean$week),]
View(data_clean2)
# Read Clean
data = read.csv("../Walmart.csv", header = T)
head(data,3)
# Create Time Target (143 weeks, 45 stores in total)
data$week = rep(1:143,45)
require(dplyr)
data_clean <- data%>%group_by(Date) %>%
summarise(Weekly_Sales = mean(Weekly_Sales),
week = mean(week),
Holiday_Flag = mean(Holiday_Flag),
Temperature = mean(Temperature),
Fuel_Price = mean(Fuel_Price),
CPI = mean(CPI),
Unemployment = mean(Unemployment),
.groups = 'drop')
data_clean2 <- data_clean[order(data_clean$week),]
View(data_clean2)
# Data Weekly Average Calculation
data_clean = aggregate(data, list(DateAgg = data$Date), mean)
index.ord = order(data_clean$week)
data_clean = data_clean[index.ord,]
data_clean = data_clean[,c(1,4,5,6,7,8,9)]
# New Dataset: Only Include DataAgg, Weekly_Sales, Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment
head(data_clean,5)
View(data_clean)
Unemployment.ts = ts(data_clean$Unemployment, start = c(2010,6), frequency =52)
library(forecast)
WeeklySales.ts = ts(data_clean$Weekly_Sales, start = c(2010,6), frequency = 52)
autoplot(WeeklySales.ts)
autoplot(Unemployment.ts)
# Read Clean
data = read.csv("../Walmart.csv", header = T)
head(data,3)
# Create Time Target (143 weeks, 45 stores in total)
data$week = rep(1:143,45)
data[,143]
data[:,143]
data[,1:143]
data[1:143]
# Read Clean
data = read.csv("../Walmart.csv", header = T)
data[1:143:]
data[1:143,]
data <- data[1:143,]
data_clean <- data%>%group_by(Date) %>%
summarise(Weekly_Sales = mean(Weekly_Sales),
week = mean(week),
Holiday_Flag = mean(Holiday_Flag),
Temperature = mean(Temperature),
Fuel_Price = mean(Fuel_Price),
CPI = mean(CPI),
Unemployment = mean(Unemployment),
.groups = 'drop')
data <- data[1:143,]
data_clean <- data[1:143,]
WeeklySales.ts = ts(data_clean$Weekly_Sales, start = c(2010,6), frequency = 52)
autoplot(WeeklySales.ts)
Unemployment.ts = ts(data_clean$Unemployment, start = c(2010,6), frequency =52)
autoplot(Unemployment.ts)
# Read Clean
data = read.csv("../Walmart.csv", header = T)
head(data,3)
# Read Clean
data = read.csv("..\Walmart.csv", header = T)
# Read Clean
data = read.csv("../Walmart.csv", header = T)
head(data,3)
# Create Time Target (143 weeks, 45 stores in total)
data$week = rep(1:143,45)
# Create Time Target (143 weeks, 45 stores in total)
data$week = rep(1:143,45)
require(dplyr)
data_clean <- data%>%group_by(Date) %>%
summarise(Weekly_Sales = mean(Weekly_Sales),
week = mean(week),
Holiday_Flag = mean(Holiday_Flag),
Temperature = mean(Temperature),
Fuel_Price = mean(Fuel_Price),
CPI = mean(CPI),
Unemployment = mean(Unemployment),
.groups = 'drop')
data_clean <- data_clean[order(data_clean$week),]
data_clean
# Data Weekly Average Calculation
# data_clean = aggregate(data, list(DateAgg = data$Date), mean)
# index.ord = order(data_clean$week)
# data_clean = data_clean[index.ord,]
# data_clean = data_clean[,c(1,4,5,6,7,8,9)]
# New Dataset: Only Include DataAgg, Weekly_Sales, Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment
head(data_clean,5)
WeeklySales.ts = ts(data_clean$Weekly_Sales, start = c(2010,6), frequency = 52)
plot(WeeklySales.ts)
n = length(WeeklySales.ts)
nValid = length(c(101:143))
nTrain = n - nValid
WeeklySales.train = window(WeeklySales.ts,
start = c(2010,6),
end = c(2010,5+nTrain))
WeeklySales.test = window(WeeklySales.ts,
start = c(2010,5+nTrain+1))
WeeklySales.train
WeeklySales.test
dWeeklySales.ts = diff(WeeklySales.ts,1)
autoplot(dWeeklySales.ts)
library(ggplot2)
library(forecast)
library(zoo)
dWeeklySales.ts = diff(WeeklySales.ts,1)
autoplot(dWeeklySales.ts)
n = length(dWeeklySales.ts)
nValid = length(c(100:142))
par(mfrow = c(1,2))
Acf(WeeklySales.train, 36, main = "")
Pacf(WeeklySales.train, 36, main = "")
par(mfrow = c(1,1))
setwd("~/Desktop/DSO 522/Week 10")
data <- read.table("w-gasoline.txt")
#head(data)
plot.ts(data$V1)
ldata = log(data$V1) #Only log the first column of the data
tdx=c(1:717)/52+1997
plot.ts(tdx,ldata,type="l")
ldata.ts = ts(ldata, start = c(1997), frequency = 365.25/7)
library(forecast)
autoplot(ldata.ts)
dldata = diff(ldata.ts,1)
autoplot(dldata)
n = length(dldata)
stepsAhead = 16
train.ts = window(dldata,end=c(1997, n-stepsAhead+1), frequency = 365.25/7)
test.ts = window(dldata,start=c(1997,n-stepsAhead+2),frequency = 365.25/7)
# you need to use train.ts here
par(mfrow = c(1,2))
Acf(train.ts, 60)
Pacf(train.ts, 20)
par(mfrow=c(1,1))
Pacf(train.ts, 60)
# you need to use train.ts here
par(mfrow = c(1,2))
Acf(train.ts, 60)
Pacf(train.ts, 60)
par(mfrow=c(1,1))
data <- read.table("Case 1.txt", header = T)
head(data)
data.ts <- ts(data,start = c(1998,1), frequency = 12)
plot(data.ts/1000,main= "Mr. Tux monthly sales volume",
ylab = "Volume in 1000's")
train.ts = window(data.ts, end = c(2004,12))
valid.ts = window(data.ts, start= c(2005,1))
library(forecast)
# fit the model
dtrain <- diff(train.ts, 1) #just remove the linear trend
autoplot(dtrain) # dtrended data
par(mfrow = c(1,2))
Acf(dtrain, 36, main = "")
Pacf(dtrain, 36, main = "")
setwd("~/Desktop/time_series_project")
library(ggplot2)
library(forecast)
library(zoo)
# Read Clean
data = read.csv("../Walmart.csv", header = T)
head(data,3)
setwd("~/Desktop/time_series_project/code")
# Read Clean
data = read.csv("../Walmart.csv", header = T)
head(data,3)
# Create Time Target (143 weeks, 45 stores in total)
data$week = rep(1:143,45)
require(dplyr)
data_clean <- data%>%group_by(Date) %>%
summarise(Weekly_Sales = mean(Weekly_Sales),
week = mean(week),
Holiday_Flag = mean(Holiday_Flag),
Temperature = mean(Temperature),
Fuel_Price = mean(Fuel_Price),
CPI = mean(CPI),
Unemployment = mean(Unemployment),
.groups = 'drop')
data_clean <- data_clean[order(data_clean$week),]
# Data Weekly Average Calculation
# data_clean = aggregate(data, list(DateAgg = data$Date), mean)
# index.ord = order(data_clean$week)
# data_clean = data_clean[index.ord,]
# data_clean = data_clean[,c(1,4,5,6,7,8,9)]
# New Dataset: Only Include DataAgg, Weekly_Sales, Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment
head(data_clean,5)
WeeklySales.ts = ts(data_clean$Weekly_Sales, start = c(2010,6), frequency = 52)
plot(WeeklySales.ts)
n = length(WeeklySales.ts)
nValid = length(c(101:143))
nTrain = n - nValid
dWeeklySales.ts = diff(WeeklySales.ts,1)
autoplot(dWeeklySales.ts)
n = length(dWeeklySales.ts)
nValid = length(c(100:142))
nTrain = n - nValid
nTrain = n - nValid
WeeklySales.train = window(dWeeklySales.ts,
start = c(2010,7),
end = c(2010,6+nTrain))
WeeklySales.test = window(dWeeklySales.ts,
start = c(2010,6+nTrain+1))
par(mfrow = c(1,2))
Acf(WeeklySales.train, 36, main = "")
Pacf(WeeklySales.train, 36, main = "")
par(mfrow = c(1,1))
Acf(WeeklySales.train, 60, main = "")
Pacf(WeeklySales.train, 60, main = "")
par(mfrow = c(1,1))
par(mfrow = c(1,2))
Acf(WeeklySales.train, 60, main = "")
Pacf(WeeklySales.train, 60, main = "")
par(mfrow = c(1,1))
Acf(WeeklySales.train, 120, main = "")
Pacf(WeeklySales.train, 120, main = "")
par(mfrow = c(1,1))
par(mfrow = c(1,2))
Acf(WeeklySales.train, 120, main = "")
Pacf(WeeklySales.train, 120, main = "")
par(mfrow = c(1,1))
par(mfrow = c(1,2))
Acf(WeeklySales.train, 200, main = "")
Pacf(WeeklySales.train, 200, main = "")
par(mfrow = c(1,1))
par(mfrow = c(1,2))
Acf(WeeklySales.train, 200, main = "")
Pacf(WeeklySales.train, 200, main = "")
par(mfrow = c(1,1))
par(mfrow = c(1,2))
Acf(WeeklySales.train, main = "")
Pacf(WeeklySales.train, main = "")
par(mfrow = c(1,1))
Acf(WeeklySales.train,100, main = "")
par(mfrow = c(1,2))
Acf(WeeklySales.train,120, main = "")
Pacf(WeeklySales.train, 120,main = "")
par(mfrow = c(1,1))
par(mfrow = c(1,2))
Acf(WeeklySales.train,53, main = "")
Pacf(WeeklySales.train, 53,main = "")
par(mfrow = c(1,1))
Acf(WeeklySales.train,110, main = "")
par(mfrow = c(1,2))
Acf(WeeklySales.train,100, main = "")
Pacf(WeeklySales.train, 100,main = "")
par(mfrow = c(1,1))
par(mfrow = c(1,2))
Acf(WeeklySales.train,52, main = "")
Pacf(WeeklySales.train, 52,main = "")
par(mfrow = c(1,1))
# Remove the trend from of the time series data
dWeeklySales.ts = diff(WeeklySales.ts,1)
autoplot(dWeeklySales.ts)
# Train Test Split
n = length(dWeeklySales.ts)
# Train Test Split
dn = length(dWeeklySales.ts)
dValid = length(c(100:142))
dTrain = n - dValid
dWeeklySales.train = window(dWeeklySales.ts,
start = c(2010,7),
end = c(2010,6+nTrain))
dWeeklySales.test = window(dWeeklySales.ts,
start = c(2010,6+nTrain+1))
par(mfrow = c(1,2))
par(mfrow = c(1,2))
Acf(dWeeklySales.train,52, main = "")
Pacf(dWeeklySales.train, 52,main = "")
par(mfrow = c(1,1))
m1 = Arima(dWeeklySales.train,
order = c(1,0,1))
dValid
m1.predict <- forecast(m2, h = 43, level = 0)
autoplot(dWeeklySales.train)+
autolayer(dWeeklySales.test, series = 'Actual')+
autolayer(m1.predict, series = 'Predicted')
# ARMA(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(3,1,1))
m1.predict <- forecast(m2, h = 43, level = 0)
autoplot(dWeeklySales.train)+
autolayer(dWeeklySales.test, series = 'Actual')+
autolayer(m1.predict, series = 'Predicted')
# ARMA(1,0,1)x(1,0,1)
m2 = Arima(dWeeklySales.train,
order = c(3,0,1),
seasonal = list(order = c(1,0,1),period = 52))
# ARMA(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(3,0,1))
m1.predict <- forecast(m1, h = 43, level = 0)
autoplot(dWeeklySales.train)+
autolayer(dWeeklySales.test, series = 'Actual')+
autolayer(m1.predict, series = 'Predicted')
# ARMA(1,0,1)x(1,0,1)
m2 = Arima(dWeeklySales.train,
order = c(3,0,1),
seasonal = list(order = c(1,0,1),period = 52))
m2.predict <- forecast(m2, h = 43, level = 0)
autoplot(dWeeklySales.train)+
autolayer(dWeeklySales.test, series = 'Actual')+
autolayer(m2.predict, series = 'Predicted')
autoplot(dWeeklySales.test, series = 'Actual')+
autolayer(m2.predict, series = 'Predicted')
autoplot(dWeeklySales.test, series = 'Actual')+
autolayer(m1.predict, series = 'Predicted')
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(1,0,1),
seasonal = list(order = c(1,0,1),period = 52))
m1.predict <- forecast(m1, h = 43, level = 0)
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(1,0,1),
seasonal = list(order = c(1,0,1),period = 52))
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(1,0,1),
seasonal = list(order = c(1,0,1),period = 52))
autoplot(dWeeklySales.test, series = 'Actual')+
autolayer(m1.predict, series = 'Predicted')
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(1,0,1),
seasonal = list(order = c(1,0,1),period = 52))
# Remove the trend from of the time series data
dWeeklySales.ts = diff(WeeklySales.ts,1)
autoplot(dWeeklySales.ts)
# Train Test Split
dn = length(dWeeklySales.ts)
dValid = length(c(100:142))
dTrain = n - dValid
dWeeklySales.train = window(dWeeklySales.ts,
start = c(2010,7),
end = c(2010,6+nTrain))
dWeeklySales.test = window(dWeeklySales.ts,
start = c(2010,6+nTrain+1))
par(mfrow = c(1,2))
Acf(dWeeklySales.train,52, main = "")
Pacf(dWeeklySales.train, 52,main = "")
par(mfrow = c(1,1))
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(1,0,1),
seasonal = list(order = c(1,0,1),period = 52))
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(3,0,1),
seasonal = list(order = c(1,0,1),period = 52))
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(1,0,1),
seasonal = list(order = c(1,0,1),period = 52))
m1.predict <- forecast(m1, h = 43, level = 0)
autoplot(dWeeklySales.test, series = 'Actual')+
autolayer(m1.predict, series = 'Predicted')
checkresiduals(m1.predict, dWeeklySales.test)
par(mfrow = c(1,2))
Acf(dWeeklySales.train,52, main = "")
Pacf(dWeeklySales.train, 52,main = "")
par(mfrow = c(1,1))
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(0,0,1),
seasonal = list(order = c(1,0,1),period = 52))
m1.predict <- forecast(m1, h = 43, level = 0)
autoplot(dWeeklySales.test, series = 'Actual')+
autolayer(m1.predict, series = 'Predicted')
checkresiduals(m1.predict, dWeeklySales.test)
autoplot(dWeeklySales.test, series = 'Actual')+
autolayer(m1.predict, series = 'Predicted')
accuracy(m1.predict, dWeeklySales.test)
checkresiduals(m1.predict)
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(1,0,1),
seasonal = list(order = c(1,0,1),period = 52))
m1.predict <- forecast(m1, h = 43, level = 0)
accuracy(m1.predict, dWeeklySales.test)
# ARMA(1,0,1)x(1,0,1)
m1 = Arima(dWeeklySales.train,
order = c(1,0,1),
seasonal = list(order = c(1,0,1),period = 52))
m1.predict <- forecast(m1, h = 43, level = 0)
autoplot(dWeeklySales.test, series = 'Actual')+
autolayer(m1.predict, series = 'Predicted')
accuracy(m1.predict, dWeeklySales.test)
checkresiduals(m1.predict)
