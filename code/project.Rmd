---
title: 'DSO 522: Final Project - Walmart Sales Prediction'
author: 'Group 8'
output:
  pdf_document: default
  word_document: default
header-includes: \usepackage{color}
editor_options: 
  chunk_output_type: console
---

- Library Import 
```{r}
library(ggplot2)
library(forecast)
library(zoo)
library(dplyr)
library(skimr)
library(astsa)
```

## EDA
Exploring the dataset
```{r}
# Explore the original dataset
data = read.csv("Walmart.csv", header = T)
head(data,3)

# Explore the dataset
# 1. Dimension of the dataset
dim(data)

#2. summary of the dataset
summary(data)

#3. Skim summary of the dataset
skim(data)
```


## Data Preparation

Data Cleaning
```{r}
# Read Clean
data = read.csv("Walmart.csv", header = T)
head(data,3)

# Create Time Target (143 weeks, 45 stores in total)
data$week = rep(1:143,45)

# Install dplyr 
require(dplyr)

data_clean <- data%>%group_by(Date) %>%
  summarise(Weekly_Sales = mean(Weekly_Sales),
            week = mean(week),
            Holiday_Flag = mean(Holiday_Flag),
            Temperature = mean(Temperature),
            Fuel_Price = mean(Fuel_Price),
            CPI = mean(CPI), 
            Unemployment = mean(Unemployment),
            .groups = 'drop')

data_clean <- data_clean[order(data_clean$week),]
# View(data_clean)

# New Dataset: Only Include DataAgg, Weekly_Sales, Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment
head(data_clean,5)
```

Transforming to Time Series and Plot each variable
```{r}
# Plot Weekly Sale
WeeklySales.ts = ts(data_clean$Weekly_Sales, start = c(2010,6), frequency = 52)
plot(WeeklySales.ts, ylab='Weekly Sales')

# Plot Temperature
Temp.ts = ts(data_clean$Temperature, start = c(2010,6), frequency = 52)
plot(Temp.ts, ylab='Temperature')

# Plot Fuel_Price
Fuel.ts = ts(data_clean$Fuel_Price, start = c(2010,6), frequency = 52)
plot(Fuel.ts, ylab='Fuel_Price')

# Plot CPI
Cpi.ts = ts(data_clean$CPI, start = c(2010,6), frequency = 52)
plot(Cpi.ts, ylab='CPI')

# Plot Unemployment
Rate.ts = ts(data_clean$Unemployment, start = c(2010,6), frequency = 52)
plot(Rate.ts, ylab='Unemployment')

# Plot store
h=hist(data$Store, main="The most frequent store",xlab="The store number",xlim=c(5,45), ylim=c(1,150), breaks=45)
text(h$mids,h$counts,labels=h$counts, adj=c(0.5, -0.5))

# Plot Holiday Flag
h=hist(data$Holiday_Flag, ylim=c(1,6500), breaks=2, main='Frequency of Holiday Flag', xlab='Holiday Flag')
text(h$mids,h$counts,labels=h$counts, adj=c(0.5, -0.5))

# Plot Date
temp_df=as.data.frame(table(data$Date))
barplot(temp_df$Freq, ylim=c(0,50), xlim=c(1,20), ylab="Frequency", xlab="Date", main="Frequency of each Date")
plot(temp_df, xlim=c(1,20), ylab="Frequency", xlab="Date", main="Frequency of Date")
```

Train Test Split
training set: '2010-02-05' to '2012-02-03' (105 weeks)
validation set: '2012-02-03' to '2012-10-26' (38 weeks)

```{r}
n = length(WeeklySales.ts)
nValid = 38
nTrain = n - nValid

WeeklySales.train = window(WeeklySales.ts, 
                          start = c(2010,6),
                          end = c(2010,5+nTrain))
WeeklySales.test = window(WeeklySales.ts,
                          start = c(2010,5+nTrain+1))
WeeklySales.train
WeeklySales.test
```


## Naive & Seasonal Forecast
```{r}
# Naive Forecast
naive = naive(WeeklySales.train, h=length(WeeklySales.test))
accuracy(naive, WeeklySales.test)

# Seasonal Forecast
seasonal = snaive(WeeklySales.train, h= length(WeeklySales.test))
accuracy(seasonal, WeeklySales.test)

# Graph of Naive and seasonal forecast
autoplot(WeeklySales.train)+
  autolayer(naive, series ="Naive Forecast", PI=FALSE)+
  autolayer(seasonal, series="Seasonal Forecast", PI=FALSE)+
  autolayer(WeeklySales.test, series="Observed")

```
For Naive forecast, training set RMSE is 158487.6, and testing RMSE is 49706.2. 
For Seasonla Forecast, training set RMSE is 43443.57, and testing RMSE is 45729.70. 


## Exponential Smoothing & Moving Average/Trailing

Moving Average
```{r}
#install.packages("patchwork")
library(patchwork)

#Moving Average
ma.centered4 = ma(WeeklySales.ts, order = 4, centre = TRUE)
ma.centered6 = ma(WeeklySales.ts, order = 6, centre = TRUE)
ma.centered12 = ma(WeeklySales.ts, order = 12, centre = TRUE)
ma.centered18 = ma(WeeklySales.ts, order = 18, centre = TRUE)
#Plot Centered MA
ma4 = autoplot(WeeklySales.ts, xlab = "Time") +
  autolayer(ma.centered4, lwd = 1.5, show.legend = FALSE) +
  labs(title = "MA 4")

ma6 = autoplot(WeeklySales.ts,  xlab = "Time") +
  autolayer(ma.centered6, lwd = 1.5, show.legend = FALSE) +
  labs(title = "MA 6")

ma12 = autoplot(WeeklySales.ts, xlab = "Time") +
  autolayer(ma.centered12, lwd = 1.5, show.legend = FALSE) +
  labs(title = "MA 12")

ma18 = autoplot(WeeklySales.ts, xlab = "Time") +
  autolayer(ma.centered18, lwd = 1.5, show.legend = FALSE) +
  labs(title = "MA 18")
  

(ma4 | ma6) /
(ma12 | ma18)
```

Trailing Moving Average
```{r}
ma.trailing = rollmean(WeeklySales.ts, k = 6, align = "right")

autoplot(WeeklySales.ts, ylab = "Weekly Sales", xlab = "Time", col="Black") +
  autolayer(ma.centered6, series = "Moving Average", lwd = 1.5)+
  autolayer(ma.trailing, series = "Trailing MA", lwd = 1.5)
```


```{r}
#Fit a trailing average smoother
ma.trailing = rollmean(WeeklySales.train, k = 6, align = "right")

#Find the last moving average in the training period
last.ma = tail(ma.trailing, 1)

#Find the last moving average as the prediction for each week in validation period
ma.trailing.pred <- ts(rep(last.ma, nValid),
                      start = c(2010,6 + nTrain+1),
                      end = c(2010,5 + nTrain+nValid),
                      frequency = 52)
#Actual observed average over the validation period
valid.mean <- ts(rep(mean(WeeklySales.test), nValid),
                 start = c(2010,6+ nTrain+1),
                 end = c(2010,5+ nTrain+nValid),
                 frequency = 52)

#plot
autoplot(WeeklySales.ts, ylab = "Weekly Sales")+
  autolayer(ma.trailing, series = "MA Trailing", lwd = 1.5)+
  autolayer(ma.trailing.pred, series = "Predicted", lwd = 1.5)+
  autolayer(valid.mean, series = "Actual Mean", lwd = 1.5)
```

```{r}
# k = 4
nValid = 38
ma.trail.pred.rolling <- rep(NA, nValid)

for (i in 1:nValid){
  nTrain = n-nValid+(i-1)
  
  train.ts <- window(WeeklySales.ts, 
                     start = c(2010,6),
                     end = c(2010,5+nTrain),
                     frequency = 52)
  
  ma.trailing.roll = rollmean(train.ts, k = 4, align = "right")
  last.ma = tail(ma.trailing.roll,1)
  ma.trail.pred.rolling[i] = last.ma
}

ma.roll.ts4 = ts(ma.trail.pred.rolling,
                start = c(2010, 5+length(WeeklySales.ts) - nValid +1),
                frequency = 52)

valid.mean = ts(rep(mean(valid.ts), nValid),
                start = c(2010, length(WeeklySales.ts) - nValid +1),
                frequency = 52)
```

```{r}
k4 = autoplot(WeeklySales.ts, ylab = "Weekly Sales") +
  autolayer(ma.trailing, series = "Trailing", lwd = 1.5)+
  autolayer(WeeklySales.test, series = "Test")+
  autolayer(ma.roll.ts4, series = "Rolling", lwd = 1.5)+
  labs(title = "Trailing 4")
```

```{r}
# k = 6
nValid = 38
ma.trail.pred.rolling <- rep(NA, nValid)

for (i in 1:nValid){
  nTrain = n-nValid+(i-1)
  
  train.ts <- window(WeeklySales.ts, 
                     start = c(2010,6),
                     end = c(2010,5+nTrain),
                     frequency = 52)
  
  ma.trailing.roll = rollmean(train.ts, k = 6, align = "right")
  last.ma = tail(ma.trailing.roll,1)
  ma.trail.pred.rolling[i] = last.ma
}

ma.roll.ts6 = ts(ma.trail.pred.rolling,
                start = c(2010, 5+length(WeeklySales.ts) - nValid +1),
                frequency = 52)

valid.mean = ts(rep(mean(valid.ts), nValid),
                start = c(2010, length(WeeklySales.ts) - nValid +1),
                frequency = 52)
```

```{r}
k6 = autoplot(WeeklySales.ts, ylab = "Weekly Sales") +
  autolayer(ma.trailing, series = "Trailing", lwd = 1.5)+
  autolayer(WeeklySales.test, series = "Test")+
  autolayer(ma.roll.ts6, series = "Rolling", lwd = 1.5)+
  labs(title = "Trailing 6")
```

```{r}
# k = 12
nValid = 38
ma.trail.pred.rolling <- rep(NA, nValid)

for (i in 1:nValid){
  nTrain = n-nValid+(i-1)
  
  train.ts <- window(WeeklySales.ts, 
                     start = c(2010,6),
                     end = c(2010,5+nTrain),
                     frequency = 52)
  
  ma.trailing.roll = rollmean(train.ts, k = 12, align = "right")
  last.ma = tail(ma.trailing.roll,1)
  ma.trail.pred.rolling[i] = last.ma
}

ma.roll.ts12 = ts(ma.trail.pred.rolling,
                start = c(2010, 5+length(WeeklySales.ts) - nValid +1),
                frequency = 52)

valid.mean = ts(rep(mean(valid.ts), nValid),
                start = c(2010, length(WeeklySales.ts) - nValid +1),
                frequency = 52)
```

```{r}
k12 = autoplot(WeeklySales.ts, ylab = "Weekly Sales") +
  autolayer(ma.trailing, series = "Trailing", lwd = 1.5)+
  autolayer(WeeklySales.test, series = "Test")+
  autolayer(ma.roll.ts12, series = "Rolling", lwd = 1.5)+
  labs(title = "Trailing 12")
```

```{r}
# k = 18
nValid = 38
ma.trail.pred.rolling <- rep(NA, nValid)

for (i in 1:nValid){
  nTrain = n-nValid+(i-1)
  
  train.ts <- window(WeeklySales.ts, 
                     start = c(2010,6),
                     end = c(2010,5+nTrain),
                     frequency = 52)
  
  ma.trailing.roll = rollmean(train.ts, k = 18, align = "right")
  last.ma = tail(ma.trailing.roll,1)
  ma.trail.pred.rolling[i] = last.ma
}

ma.roll.ts18 = ts(ma.trail.pred.rolling,
                start = c(2010, 5+length(WeeklySales.ts) - nValid +1),
                frequency = 52)

valid.mean = ts(rep(mean(valid.ts), nValid),
                start = c(2010, length(WeeklySales.ts) - nValid +1),
                frequency = 52)
```


```{r}
k18 = autoplot(WeeklySales.ts, ylab = "Weekly Sales") +
  autolayer(ma.trailing, series = "Trailing", lwd = 1.5)+
  autolayer(WeeklySales.test, series = "Test")+
  autolayer(ma.roll.ts18, series = "Rolling", lwd = 1.5)+
  labs(title = "Trailing 18")
```

```{r}
(k4 | k6) /
(k12 | k18)
```

Accuracy
```{r}
accuracy(WeeklySales.test, ma.roll.ts4)
accuracy(WeeklySales.test, ma.roll.ts6)
accuracy(WeeklySales.test, ma.roll.ts12)
accuracy(WeeklySales.test, ma.roll.ts18)
```

```{r}
#Model 1
data.diff.ts = diff(WeeklySales.ts, lag=1)
#data.diff.ts<- diff(lag_1, lag=12)

# set up the training and testing sets

nValid = 38

dtrain.ts=window(data.diff.ts, start=c(2010, 7),
                 end=c(2010, 6+length(data.diff.ts)-nValid),
                 frequency = 52) 

dvalid.ts=window(data.diff.ts, start=c(2010, 6+length(data.diff.ts)-nValid+1),
                 frequency = 52)

length(dtrain.ts)
length(dvalid.ts)

ann <- ets(dtrain.ts, model = "ANN")
ann.pred <- forecast.ets(ann, h=nValid, level=0)

#plot 
autoplot(data.diff.ts) +
  autolayer(ann.pred, series = "Simple Exp. Smoothing")

accuracy(ann.pred, dvalid.ts)
```

```{r}
model <- tbats(WeeklySales.ts)
fc2 <- forecast(model, h=38)
plot(fc2)
```
```{r}
#Holt's Linear Trend Model
nValid = 38

train.ts=window(WeeklySales.ts, 
                start=c(2010, 7), 
                end=c(2010, 6+length(WeeklySales.ts)-nValid),
                frequency = 52)

valid.ts=window(WeeklySales.ts, 
                start=c(2010, 6+length(WeeklySales.ts)-nValid+1), 
                frequency = 52)

aan <- ets(train.ts, model = "AAN")
aan.pred <- forecast.ets(aan, h=nValid, level=0)

autoplot(WeeklySales.ts) +
  autolayer(aan.pred, series = "AAN pred", col="blue")

accuracy(aan.pred, valid.ts)
```

## ARIMA/ Seasonal ARIMA
Step 1: Check whether the trend has 
```{r}
# Check whether the data is static. 
autoplot(WeeklySales.ts)
```
According to the plot, there is no significant trend component in the time series data. Therefore, we don't need to use differencing techniques to detrend data. 


Step 2: Use the training set and plot the ACF and PACF functions of the growth rate of the weekly sales found in previous part.
```{r}
par(mfrow = c(1,2))
Acf(WeeklySales.train,104, main = "Training Set (104 Lag)")
Pacf(WeeklySales.train,104,main = "Testing Set (104 Lag)")
par(mfrow = c(1,1))
```

```{r}
par(mfrow = c(1,2))
Acf(WeeklySales.train,51, main = "Training Set (51 Lag)")
Pacf(WeeklySales.train,51,main = "Testing Set (51 Lag)")
par(mfrow = c(1,1))
```

According to the ACF and PACF plots, the ACF is approximately tailing off and PACF is cutting off within the first season.Both ACF and PACF is cutting off after the first season. 

We will try SARIMA(1,0,0)x(1,0,0) first.

Step 3: Modeling
```{r}
# SARMA(1,0,0)x(1,0,0)
m1 = Arima(WeeklySales.train,
           order = c(1,0,0),
           seasonal = list(order = c(1,0,0),period = 52))
m1.predict <- forecast(m1, h = nValid, level = 0)

autoplot(WeeklySales.train, ylab = 'Weekly Sales',
main = 'Model: SARIMA(1,0,0)x(1,0,0)[52]')+
  autolayer(WeeklySales.test, series = 'Actual')+
  autolayer(m1.predict, series = 'Predicted')+
  autolayer(m1$fitted,series = 'Fitted')

accuracy(m1.predict, WeeklySales.test)
checkresiduals(m1)
```
 For SARMA(1,0,0)x(1,0,0)[52], the RMSE in training set is 41053.65 and RMSE in Test set is 44425.09. 

```{r}
# SARMA(5,0,0)x(1,0,0)
m2 = Arima(WeeklySales.train, 
           order = c(5,0,0),
           seasonal = list(order = c(1,0,0),period = 52))
m2.predict <- forecast(m2, h = nValid, level = 0)

autoplot(WeeklySales.train, ylab = 'WeeklySales',
main = 'Model: SARIMA(5,0,0)x(1,0,0)[52]')+
  autolayer(WeeklySales.test, series = 'Actual')+
  autolayer(m2.predict, series = 'Predicted')+
  autolayer(m2$fitted,series = 'Train')

accuracy(m2.predict, WeeklySales.test)

checkresiduals(m2.predict)
```
For SARMA(5,0,0)x(1,0,0)[52], the RMSE in training set is 42097.27 and RMSE in Test set is 44540.73.

```{r}
# SARMA(5,0,0)x(1,0,1)
m3 = Arima(WeeklySales.train, 
           order = c(5,0,0),
           seasonal = list(order = c(1,0,1),period = 52))
m3.predict <- forecast(m3, h = nValid, level = 0)

autoplot(WeeklySales.train, ylab = 'WeeklySales',
main = 'Model: SARIMA(5,0,0)x(1,0,1)[52]')+
  autolayer(WeeklySales.test, series = 'Actual')+
  autolayer(m3.predict, series = 'Predicted')+
  autolayer(m3$fitted,series = 'Fitted')

accuracy(m3.predict, WeeklySales.test)

checkresiduals(m3.predict)
```
For SARMA(5,0,0)x(1,0,1)[52], the RMSE in training set is 42055.07 and RMSE in Test set is 45170.57.

```{r}
# SARMA(5,0,1)x(1,0,1)
m4 = Arima(WeeklySales.train, 
           order = c(5,0,1),
           seasonal = list(order = c(1,0,1),period = 52))
m4.predict <- forecast(m4, h = nValid, level = 0)

autoplot(WeeklySales.train, ylab = 'WeeklySales',
main = 'Model: SARIMA(5,0,1)x(1,0,1)[52]')+
  autolayer(m4$fitted,series = 'Fitted')+
  autolayer(WeeklySales.test, series = 'Actual')+
  autolayer(m4.predict, series = 'Predicted')
  

accuracy(m4.predict, WeeklySales.test)

checkresiduals(m4.predict)
```
For SARMA(5,0,1)x(1,0,1)[52], the RMSE in training set is 42052.92 and RMSE in Test set is 45152.82.

```{r}
# SARMA(5,0,5)x(1,0,1)
m5 = Arima(WeeklySales.train, 
           order = c(5,0,5),
           seasonal = list(order = c(1,0,1),period = 52))
m5.predict <- forecast(m5, h = nValid, level = 0)

autoplot(WeeklySales.train, ylab = 'Weekly Sales',
main = 'Model: SARIMA(5,0,5)x(1,0,1)[52]')+
  autolayer(m5$fitted,series = 'Fitted')+
  autolayer(WeeklySales.test, series = 'Actual')+
  autolayer(m5.predict, series = 'Predicted')
  

accuracy(m5.predict, WeeklySales.test)

checkresiduals(m5.predict)
```
For SARMA(5,0,5)x(1,0,1)[52], the RMSE in training set is 40241.62 and RMSE in Test set is 47998.56.

## Multiple Linear Regression

Step1: Add two additional features
(1) Capture abnormal rise in sales from Thanksgiving to Chirstmas each year.
```{r}
data_clean$is_Xmas_BF = rep(0, 143)
for (week_flag in c(42,43,46,47))
{
  data_clean$is_Xmas_BF = ifelse(data_clean$is_Xmas_BF ==1,1,ifelse((data_clean$week-week_flag)/52==0|(data_clean$week-week_flag)/52==1,1,0))
}
```
(2) Capture abnormal drop in sales 5 weeks before Thanksgiving and 4 weeks after Christmas.
```{r}
data_clean$is_NY = rep(0, 143)
for (week_flag in c(35,36,37,38,39,48,49,50,51))
{
  data_clean$is_NY = ifelse(data_clean$is_NY ==1,1,ifelse((data_clean$week-week_flag)/52==0|(data_clean$week-week_flag)/52==1,1,0))
}
```

Step2: Construct time series objects we'll use in regression model.
```{r}
HolidayFlag.ts = ts(data_clean$Holiday_Flag, start = c(2010,6), frequency = 52)
Xmas.ts = ts(data_clean$is_Xmas_BF, start = c(2010,6), frequency = 52)
Ny.ts = ts(data_clean$is_NY, start = c(2010,6), frequency = 52)
```

Step3: Explore relationships between variables and weekly sales.
```{r}
qplot(Temp.ts,WeeklySales.ts)
qplot(Fuel.ts,WeeklySales.ts)
qplot(Cpi.ts,WeeklySales.ts)
qplot(Rate.ts,WeeklySales.ts)
qplot(HolidayFlag.ts,WeeklySales.ts)
qplot(Xmas.ts,WeeklySales.ts)
qplot(Ny.ts, WeeklySales.ts)
```
For numeric variables, we do not find obvious trends. For dummy variables, we find positive relationship with HolidayFlag.ts and
Fuel.ts variables as well as negative relationship with Ny.ts. Therefore, we want to test the lag reationship for those numeric
variables seperatly in the next part.

Step4: Test CCF for numerical variables.
```{r}
# 20/42 lag should be significant
Ccf(Temp.ts, WeeklySales.ts, 50)
# 31 lag should be significant, also test minimum point at time 0.
Ccf(Fuel.ts, WeeklySales.ts, 50)
# All lags within decision boundary.
Ccf(Cpi.ts, WeeklySales.ts, 50)
# All lags within decision boundary.
Ccf(Rate.ts, WeeklySales.ts, 50)
```

Step5: Test best lag variables
```{r}
library(tidyverse)
lag <- stats::lag

# test temperature
newdata1= ts.intersect(WeeklySales.ts, leadR20=lag(Temp.ts,-20), leadR42=lag(Temp.ts,-42))
# model 1
m1 = tslm(WeeklySales.ts~leadR20, data = newdata1)
summary(m1)
accuracy(m1)
# model 2
m2 = tslm(WeeklySales.ts~leadR42, data = newdata1)
summary(m2)
accuracy(m2)
# Obviously, neither model has good prediction power. However, first one is a little bit better.
```
```{r}
# test fuel
newdata2= ts.intersect(WeeklySales.ts, leadR31=lag(Fuel.ts,-31),Fuel.ts)
# model 3
m3 = tslm(WeeklySales.ts~leadR31, data = newdata2)
summary(m3)
accuracy(m3)
# model 4
m4 = tslm(WeeklySales.ts~Fuel.ts, data = newdata2)
summary(m4)
accuracy(m4)
# Obviously, neither model has good prediction power. However, first one is a little bit better.
```

Step6: Build multiple linear regression models.
```{r}
# Build Final Model
newdata= ts.intersect(WeeklySales.ts, fuel=lag(Fuel.ts,-31), temp=lag(Temp.ts,-20), holiday = HolidayFlag.ts, cpi = Cpi.ts, rate = Rate.ts, xmas = Xmas.ts, ny= Ny.ts)
# train and val
newdata.train = ts(newdata[1:74,1:8],start = c(2010, 38),frequency=52)
newdata.val = ts(newdata[75:112,1:8],start = c(2012, 8), frequency=52)

# model 5
m5 = tslm(WeeklySales.ts~ temp+fuel+xmas+ny, data = newdata.train)
summary(m5)
accuracy(m5)
m5p = predict(m5, newdata = newdata.val[,c(3,2,7,8)])
accuracy(newdata.val[,1],m5p)
# model 6
m6 = tslm(WeeklySales.ts~ temp+fuel+holiday+xmas+ny, data = newdata.train)
summary(m6)
accuracy(m6)
m6p = predict(m6, newdata = newdata.val[,c(3,2,4,7,8)])
accuracy(newdata.val[,1],m6p)
# model 7 
m7 = tslm(WeeklySales.ts~ temp+fuel+holiday+cpi+xmas+ny, data = newdata.train)
summary(m7)
accuracy(m7)
m7p = predict(m7, newdata = newdata.val[,c(3,2,4,5,7,8)])
accuracy(newdata.val[,1],m7p)
# model 8
m8 = tslm(WeeklySales.ts~ temp+fuel+holiday+cpi+rate+xmas+ny, data = newdata.train)
summary(m8)
accuracy(m8)
m8p = predict(m8, newdata = newdata.val[,c(3,2,4,5,6,7,8)])
accuracy(newdata.val[,1],m8p)
```
By balancing model complexity, robusty and accuracy, we select model 5 in this step.

Step6: Consider AR term and final results.
```{r}
checkresiduals(m5)

# imply AR5
m5New = Arima(newdata.train[,1], order = c(5,0,0), xreg=newdata.train[,c(3,2,7,8)])
checkresiduals(m5New)

m5New.predict <- forecast(m5New, xreg = newdata.val[,c(3,2,7,8)], h = 38, level = 0)
accuracy(newdata.val[,1], m5New.predict$mean)
# it's worse than the original m5, so choose m5

autoplot(WeeklySales.ts, ylab= "Weekly Sales",series = 'Actual', main="Final Models for MLR", colour ="black")+
  autolayer(m5$fitted, series = "Fitted")+
  autolayer(ts(m5p, start = c(2012,8), frequency = 52), series = 'Predicted')
```
Conclusion For Regression: m5 Model considering temperature, fuel price, x-mas and new year dummy will be the best multiple linear regression model.
